{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os, cv2, random #,re\nfrom sklearn.model_selection import train_test_split\nimport tqdm\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as Data\nimport torchvision      # 数据库模块\nimport torchvision.transforms as transforms\n\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_dir = \"../input/train/train/\"\ntest_dir = \"../input/test/test/\"\ntrain_df = pd.read_csv('../input/train.csv')\nprint(train_df.head(),'\\n')\nprint(train_df['has_cactus'].value_counts(),'\\n')\n\nprint('Num train samples:{0}'.format(len(os.listdir(train_dir))))\nprint('Num test samples:{0}'.format(len(os.listdir(test_dir))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,5,figsize=(15,3))\nfor i, idx in enumerate(train_df[train_df['has_cactus']==1]['id'][-5:]):\n    ax[i].imshow(cv2.imread(train_dir+idx)) # [...,[2,1,0]]\n    \nfig,ax = plt.subplots(1,5,figsize=(15,3))\nfor i, idx in enumerate(train_df[train_df['has_cactus']==0]['id'][-5:]):\n    ax[i].imshow(cv2.imread(train_dir+idx)) # [...,[2,1,0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.shape(cv2.imread(train_dir+idx))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Libreries\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nimport torchvision\nimport torchvision.transforms as transforms\n\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I Should learn to use this part in the future!!!\n\n# NOTE: class is inherited from Dataset !!!!!!!\nclass MyDataset(Dataset):\n    def __init__(self, df_data, data_dir = './', transform=None):\n        super().__init__() #The super function in Python can be used to gain access to inherited methods which is either from a parent (Dataset) or sibling class. \n        self.df = df_data.values\n        self.data_dir = data_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_name,label = self.df[index]\n#         img_path = os.path.join(self.data_dir, img_name)\n#         image = cv2.imread(img_path)\n        image = cv2.imread(self.data_dir+img_name)\n        if self.transform:\n            image = self.transform(image)\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyper parameters\nnum_epochs = 25\nnum_classes = 2\nbatch_size = 128\nlearning_rate = 0.002\n\n# Device configuration\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, val = train_test_split(train_df, stratify=train_df.has_cactus, test_size=0.1,random_state = 42) # stratify=train_df.has_cactus: 依照train_df.has_cactus中0，1比例来保持train&val中的0，1比例\nprint(train.shape, val.shape)\n\n# transforms see: https://pytorch.org/docs/stable/torchvision/transforms.html\ntrans_train = transforms.Compose([transforms.ToPILImage(), #Converts a torch.*Tensor of shape C x H x W or a numpy ndarray \n                                                           #of shape H x W x C to a PIL Image while preserving the value range.\n                                  transforms.Pad(32, padding_mode='reflect'), # figure size becomes (32*3,32*3)\n                                  transforms.Resize(224), # resize to (224*224)\n                                  transforms.ToTensor(),#Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] \n                                                        #to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n                                  transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])])\n\ndataset_train = MyDataset(df_data=train, data_dir=train_dir, transform=trans_train)\ndataset_valid = MyDataset(df_data=val, data_dir=train_dir, transform=trans_train)\n\nloader_train = DataLoader(dataset = dataset_train, batch_size=batch_size, shuffle=True, num_workers=0)\nloader_valid = DataLoader(dataset = dataset_valid, batch_size=batch_size//2, shuffle=False, num_workers=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The Model is too big to run on Kaggle server....!!!!!!!!!!!\n\n# VGG 16\n# NOTE: class is inherited from nn.Module\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        # ancestor constructor call\n        super(SimpleCNN, self).__init__()\n        \n        self.conv1 = nn.Sequential(  # input shape (3, 96, 96)\n            nn.Conv2d(\n                in_channels=3,      # input height\n                out_channels=64,    # n_filters\n                kernel_size=3,      # filter size\n                stride=1,           # filter movement/step\n                padding=1,      # padding size\n            ),      # output shape (64, 224,224)\n            nn.BatchNorm2d(224), #batch normalization\n            nn.ReLU(),    # activation\n            nn.Conv2d(\n                in_channels=64,      # input height\n                out_channels=64,    # n_filters\n                kernel_size=3,      # filter size\n                stride=1,           # filter movement/step\n                padding=1,      # padding size\n            ),      # output shape (64, 224,224)\n            nn.BatchNorm2d(224), #batch normalization\n            nn.ReLU(),    # activation\n            nn.MaxPool2d(kernel_size=2, stride=2),    # 在 2x2 空间里向下采样, output shape (64, 112, 112)\n        )\n        \n        self.conv2 = nn.Sequential(  # input shape (32, 49, 49)\n            nn.Conv2d(64,128,3,1,1),      # output shape (128*112*112)\n            nn.BatchNorm2d(112), #batch normalization\n            nn.ReLU(),    # activation\n            nn.Conv2d(128,128,3,1,1),      # output shape (128*112*112)\n            nn.BatchNorm2d(112), #batch normalization\n            nn.ReLU(),    # activation\n            nn.MaxPool2d(2, 2),    # 在 2x2 空间里向下采样, output shape (128, 56, 56)\n        )\n        \n        self.conv3 = nn.Sequential(  # input shape (64,51,51)\n            nn.Conv2d(128,256,3,1,1),      # output shape (256,56,56)\n            nn.BatchNorm2d(56), #batch normalization\n            nn.ReLU(),    # activation\n            nn.Conv2d(256,256,3,1,1),      # output shape (256,56,56)\n            nn.BatchNorm2d(56), #batch normalization\n            nn.ReLU(),    # activation\n            nn.MaxPool2d(2, 2),    # 在 2x2 空间里向下采样, output shape (256, 28, 28)\n        )\n        \n        self.conv4 = nn.Sequential(  # input shape (128, 13, 13)\n            nn.Conv2d(256,512,3,1,1),      # output shape (512,28,28)\n            nn.BatchNorm2d(28), #batch normalization\n            nn.ReLU(),    # activation\n            nn.Conv2d(512,512,3,1,1),      # output shape (512,28,28)\n            nn.BatchNorm2d(28), #batch normalization\n            nn.ReLU(),    # activation\n            nn.MaxPool2d(2, 2),    # 在 2x2 空间里向下采样, output shape (512, 14, 14)\n        )\n        \n        self.conv5 = nn.Sequential(  # input shape (256, 7, 7)\n            nn.Conv2d(512,512,3,1,1),      # output shape (512,14,14)\n            nn.BatchNorm2d(14), #batch normalization\n            nn.ReLU(),    # activation\n            nn.Conv2d(512,512,3,1,1),      # output shape (512,14,14)\n            nn.BatchNorm2d(14), #batch normalization\n            nn.ReLU(),    # activation\n            nn.Conv2d(512,512,3,1,1),      # output shape (512,14,14)\n            nn.BatchNorm2d(14), #batch normalization\n            nn.ReLU(),    # activation\n            nn.MaxPool2d(2, 2),    # 在 2x2 空间里向下采样, output shape (512,7,7)\n        )\n        \n        self.fc1 = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(),    # activation\n            nn.Linear(4096, 4096),\n            nn.ReLU(),    # activation\n            nn.Linear(4096, 1000),\n            nn.ReLU()   # activation\n        )\n                                 \n        self.fc2 = nn.Sequential(\n            nn.Linear(1000, 2),\n            nn.Softmax()\n        )\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.conv5(x)\n        #print(x.shape) # lifehack to find out the correct dimension for the Linear Layer\n        x = x.view(-1, 512 * 7 * 7) # !!!\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return x\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use pre-trained model instead\nfrom torchvision import models\nmodel = models.vgg16_bn(pretrained = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model = model.to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001, amsgrad=True, weight_decay=1e-4)\n\n# Train the model\ntotal_step = len(loader_train)\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(loader_train):\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 100 == 0:\n            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n            correct = 0\n            total = 0\n            with torch.no_grad():\n                for steptemp,(valimages, vallabels) in enumerate(loader_valid):\n                    valimages,vallabels = valimages.cuda(),vallabels.cuda()\n                    # print(steptemp,'/25')\n                    outputs = model(valimages)\n                    _, predicted = torch.max(outputs.data, 1)\n                    total += vallabels.size(0)\n                    correct += (torch.squeeze(predicted.type(torch.LongTensor).cuda()) == vallabels).sum().item()\n            print(f'Accuracy of the network on the {total} test images: %.5f %%' % (100 * correct / total))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# generator for test data \nsub = pd.read_csv('../input/sample_submission.csv')\n\ndataset_valid = MyDataset(df_data=sub, data_dir=test_dir, transform=trans_train)\nloader_test = DataLoader(dataset = dataset_valid, batch_size=32, shuffle=False, num_workers=0)\nmodel.eval()\n\npreds = []\nfor batch_i, (data, target) in enumerate(loader_test):\n    data, target = data.cuda(), target.cuda()\n    output = model(data)\n\n    pr = output[:,1].detach().cpu().numpy()\n    for i in pr:\n        preds.append(i)\n\nsub['has_cactus'] = preds\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}